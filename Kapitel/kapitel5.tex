\chapter{Vergleich}

\section{Testumgebung}
Für den Vergleich der beiden API Ansätze wurde eine Single-Page Anwendung mit dem Vue.js Framework als Client und jeweils eine REST API und GraphQL API mit der Node.js Serverlaufzeitumgebung entwickelt.
Als Datenquelle dient zum einen eine MongoDB Datenbank, sowie Dateien im JSON Format.
Durch die Verteilung der jeweiligen Softwarekomponenten auf physikalisch unterschiedliche Rechner lassen sich mehrere Anwendungsfälle abbilden.
So wurden die Clientanwendung, die Serveranwendungen und die Datenbank in verschiedenen Kombinationen lokal und von Cloudumgebungen (Azure, Heroku, MongoDB Atlas) gehostet und ausgeführt~\ref{img:netzwerk}.
Die JSON Dateien als Alternative zur Datenbank ermöglichen es, das Kontingent der Clouddatenbank nicht unnötig zu belasten und den durch Datenbankabfragen entstehenden Overhead, auf die deutlich schnellere Dateilesezeit zu minimieren.
Bei den Messungen wurde auf das Angleichen der Testbedingungen geachtet, besonders die im Zusammenhang mit Clouddiensten gemessenen Werte sind jedoch stark von der, je nach Tageszeit unterschiedlichen, unbekannten Belastung des Dienstes abhängig.
Die verwendeten Testgeräte waren:
\begin{itemize}
  \item PC im LAN
  \item Laptop im WLAN
  \item Samsung Galaxy A3 (2017) (Smartphone1) im WLAN
  \item Samsung Galaxy S10 (Smartphone2) im WLAN und im Mobilfunknetz
\end{itemize}
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{netzwerk.png}
  \caption{Architektur der Testumgebung}\label{img:netzwerk}
\end{figure}
\section{Abfrageflexibilität}
Bei der Entwicklung von Client-Anwendungen ist die Flexibilität der genutzten API ein entscheidender Einflussfaktor.
Dabei steht meistens die Flexibilität für das Generieren der Abfragen zum Empfangen von Daten im Vordergrund, aber auch Operationen zum Modifizieren von Ressourcen müssen betrachtet werden.
\par
GraphQL wurde als Abfragesprache entwickelt.
Eines der Entwicklungsziele ist es, dass eine Clientanwendung mit einer einzigen Abfrage alle für eine Ansicht nötigen Daten erhalten kann.
Der Server gewährt Zugriff auf das Datenschema, welches alle verfügbaren Daten und deren Relationen darstellt, sowie die Einstiegspunkte (Root Query), auf deren Basis ein Client seine Anfrage aufbauen kann.
Das Schema stellt den Rahmen für alle Abfragen dar.
Alle Daten, die der Server zur Verfügung stellt, werden durch Typen und deren Felder repräsentiert.
Jedes Feld, welches eine Clientanwendung erhalten möchte, muss in der Query angegeben werden.
Es existiert keine Möglichkeit, alle Felder eines Typs zu erhalten, ohne jedes davon anzugeben, \zB{} durch Wildcard Zeichen.
Der Client ist damit eng an das Schema gekoppelt, erhält aber auch nur die Daten, die tatsächlich angefragt wurden.
Die Möglichkeit eines GraphQL-Servers, beliebige Abfragen innerhalb des Schemas auszuwerten, eignet sich besonders für öffentliche APIs, bei denen dem API-Entwickler die individuellen Anforderungen und damit die Abfragen verschiedenster Anwendungen im Voraus nicht bekannt sind.
Die Relationen zwischen den Datentypen werden durch das Schema festgelegt.
Eine Anfrage kann jedoch beliebig viele, unabhängige Queries beinhalten, \zB{} um verschiedene Daten zu erhalten, die in keiner Beziehung zueinander stehen oder deren Beziehung durch das Schema nicht dargestellt wird.
Der Server kann für jedes Feld Parameter anbieten, welche die Auswertung des Feldwertes verändern.
Über solche Feldargumente können Optionen, die Geschäftslogik darstellen, aber auch allgemeine Abfragefunktionen, wie \zB{} Sortieren~\cite[vgl.][]{GraphQL-OrderBy} und Filtern~\cite[vgl.][]{GraphQL-Filter} zur Verfügung gestellt werden.
Einem Feld \enquote{Breite} könnte beispielsweise die Maßeinheit als Option übergeben werden.
\par
Während das Anfragen von Daten sehr viel Flexibilität für Clients bietet, ist das Modifizieren von Ressourcen nach Konvention nur über einzelne Mutations möglich.
Üblicherweise wird für jede Operation (Erstellen, Verändern und Löschen) einer Ressource eine separate Mutation zur Verfügung gestellt, welche durch den Namen eindeutig identifiziert wird.
Die Antwort auf eine Mutation kann wieder ein Objekt sein und genutzt werden, um das Resultat der Operation zu übermitteln oder den neuen Stand der Ressource abzufragen.
\par

In einer REST API ist jede Ressource über einen separaten Endpunkt erreichbar.
Das Veröffentlichen einer neuen Ressource geschieht durch das Einführen eines neuen Endpunktes.
Ein Endpunkt kann alle Methoden zum Abfragen und Ändern einer Ressource bereitstellen und durch die HTTP Verben semantisch unterscheiden.
Die Antwort auf einen GET Request an einen Endpunkt enthält alle Felder der Ressource bzw.\ die komplette Repräsentation.
In Beziehung stehende Daten, die nicht Teil einer Ressource sind, müssen über mehrere Requests vom Server angefragt werden.
Der Grundgedanke von HATEOAS ist, dass diese verbundenen Ressourcen Verweise aufeinander enthalten, wodurch ihre Beziehung dargestellt wird.
Das Zusammenbauen von Requests anhand der Links in erhaltenen Ressourcen ermöglicht große Flexibilität, erfordert jedoch, dass Daten erst ausgewertet werden müssen und danach erst neue Anfragen abgesetzt werden können.
Dadurch ist das Datenmodell nicht durch ein Schema vorgegeben, sondern kann zur Laufzeit geändert und explorativ genutzt werden, da es selbstdokumentierend ist.
Oftmals ist bei der Entwicklung von Clientanwendungen die erforderliche Datenstruktur jedoch bekannt und ist es wünschenswert, möglichst alle benötigten Informationen von wenigen Endpunkten zu erhalten, um die Performance zu steigern.
Dazu gibt es verschiedene Ansätze, wie der Query-String einer URI genutzt werden kann, um in Beziehung stehende Daten mit einem einzigen Request von einem Endpunkt zu erhalten.
Weder REST noch HTTP spezifizieren Syntax und Semantik des Query Strings bzw.\ betrachten diese als Implementierungsdetail.
Query-Parameter und Matrixparameter werden häufig gebraucht, um die Möglichkeiten von Abfragesprachen für REST zu implementieren.
Sie ermöglichen \zB{} die gewünschten Felder des angefragten Objektes, ein Feld nach dem sortiert oder ein Feld und Wert nach dem gefiltert werden soll, anzugeben.
Somit können Clientanwendungen die Antwort je nach ihren Anforderungen besser beeinflussen.
Abhängig davon wie unterschiedlich diese sind, muss die Entscheidung über die Erweiterung der Parameteroptionen oder das Einführen eines separaten Endpunktes getroffen werden.
Über sogenannte \enquote{includes} lassen sich bei JSON:API verbundene Objekte in die Antwort einbeziehen.
Includes sind außerdem eine effektive Lösung für das N+1 Problem.
Diese speziellen Auswertungen des Query-Strings müssen durch den REST Server angeboten werden und sind aus Entwurfssicht ein Tausch von erhöhter Abfragekomplexität und Clientflexibilität gegen Serverperformance.
\par
Da GraphQL für die Übertragung von Daten in Textform konzipiert wurde, müssen Informationen als Text vorliegen oder serialisiert werden.
Das kann besonders beim Hochladen von Binärdaten, wie Audio- oder Videodateien, zu sehr großen Datenmengen führen.
Eine REST API kann Binärdaten mit dem MediaType \enquote{multi-part/form-data} empfangen und verarbeiten.
Für eine GraphQL API muss entweder ein Dateiupload-Service vorgeschaltet sein und nur der Link übertragen oder eine Bibliothek, wie \enquote{graphql-upload}, verwendet werden.

\section{Weiterentwicklung und Versionierung}
\par 
Langlebige Software befindet sich in ständiger Entwicklung.
Ein Server muss auf Veränderungen des der API zugrunde liegenden Datenmodells reagieren können und diese gegebenenfalls Clients zugänglich machen.
Neue Anforderungen an die API erfordern das Erweitern der Abfragemöglichkeiten oder das Verringern derselben, wenn alte Funktionalität nicht mehr unterstützt oder durch neue ersetzt werden soll.
Da jede API einen Vertrag zwischen Server und Client darstellt, sollten Veränderungen einem festgelegten Ablauf und Kommunikationskanal folgen, um sukzessive Migration zu gewährleisten und Abfragefehler zu vermeiden.
Zu diesem Zweck wird in der Softwareentwicklung häufig Versionierung verwendet, bei der durch eine Zahl oder Zahlenkombination ein bestimmter Stand der Software bereitgestellt oder abgefragt wird.
\par
Um eine REST API um zusätzliche Ressourcen zu erweitern, ist keine Versionierung notwendig.
Stattdessen wird ein neuer Endpunkt hinzugefügt und über die Verlinkung von anderen Ressourcen oder als Einstiegspunkt in der Dokumentation bekanntgemacht.
Eine API Clientanwendung sollte so entwickelt werden, dass eine Antwort ausgewertet werden kann, solange sie semantisch eindeutig verständlich ist (Postel'sches Gesetz).
Das Umordnen und Hinzufügen von Elementen innerhalb einer Antwort sollte somit nicht zu Fehlern führen und die Validierung demgegenüber tolerant sein.
Normalerweise muss erst versioniert werden, wenn keine Rückwärtskompatibilität mehr gewährleistet werden kann.
Eine neue Version einer Ressource kann über mehrere Wege bereitgestellt und angefragt werden.
\begin{enumerate}
  \item Jeder Request kann einen Accept-Header enthalten, der zur Identifikation der zu sendenden Repräsentation genutzt werden kann.
  Sendet ein Client \zB{} einen Accept-Header mit dem Wert application/vnd.format.v2+json, so kann der Server durch Content-Negotiation anhand des \enquote{v2} die zu sendende Version ermitteln.
  \item Die URI als Identifikationsmittel kann ebenfalls genutzt werden, um verschiedene Versionen einer Ressource kenntlich zu machen.
  Die Anfrage an example.com/v2/events entspricht dem Erstellen eines neuen Endpunktes.
  Der Server muss nun auf einem weiteren Endpunkt antworten können, die Komplexität jedes einzelnen Endpunktes wird jedoch nicht erhöht.
  \item Für kleine Änderungen, wie das Ändern oder Entfernen eines einzelnen Feldes, ist normalerweise kein neuer Endpunkt nötig.
  Würde für jede dieser verhältnismäßig kleinen Änderungen ein neuer Endpunkt erstellt werden, ginge schnell die Übersichtlichkeit über die Menge der Endpunkte und deren Unterschiede verloren.
  Die URI der Ressource kann für verschiedene Versionen genutzt werden und stattdessen die Versionsinformationen im Query String transportiert werden (\zB{} example.com/events?version=2).
  Diese Variante teilt den gleichen Nachteil, den alle Query String Optionen haben, dass der Serverhandler für diesen Endpunkt komplexer und die Performance verringert wird.
  Es ist denkbar, dass nicht nur jede einzelne Option geprüft werden muss, sondern dass die Option für die Version der Ressource auch Auswirkung auf andere Optionen hat, sodass der Server einen Entscheidungsbaum auswerten muss, bevor eine Antwort gesendet werden kann.
\end{enumerate}
Wurde eine neue Version einer Ressource zur Verfügung gestellt, muss diese auch erreichbar sein.
Da die Änderungen von Variante 2 und 3 sich allein auf die URI auswirken, müssen in verknüpften Ressourcen die Links zur neuen Version aktualisiert werden.
Da Header in einem Link nicht repräsentiert werden können, ist es bei der ersten Variante notwendig, dass der Client über die neue Version informiert wird und allen Anfragen an die Ressource den Accept-Header hinzufügt.
\par
Beim Entfernen von Funktionalität ist es sinnvoll, die aktuelle Nutzung derselben durch Monitoring festzustellen und notwendig, die geplanten Änderungen zu kommunizieren.
Da normalerweise die gesamte Repräsentation einer Ressource als Antwort gesendet wird, kann nur die Nutzung des Endpunktes und nicht die tatsächliche Notwendigkeit einzelner Teile der Ressource bzw.\ Felder ermittelt werden.
Das ist jedoch möglich, wenn bei jeder Anfrage mittels Includes die gewünschten Felder angegeben werden müssen.
Sollen einzelne Elemente einer Ressource nicht mehr gesendet werden, so können diese zeitweise den für den Datentyp üblichen Nullwert enthalten, bevor sie endgültig entfernt werden.
Wird ein Endpunkt der API entfernt, so sollte der Server mit dem entsprechenden HTTP Status Code (410 Gone) antworten und alle Links in verknüpften Ressourcen müssen gelöscht werden.
Ist eine Ressource lediglich unter einem anderen Endpunkt erreichbar, so kann der Code 310 \enquote{Moved Permanently} den Client automatisch zur neuen URI weiterleiten.
\par
Erklärtes Ziel von GraphQL ist es, Versionierung zu verhindern und stattdessen die API kontinuierlich, abwärtskompatibel weiterzuentwickeln.
Da jedes Feld, welches ein Client erhalten möchte, in der Query explizit angegeben werden muss, ist detailreiches Monitoring bis auf Feldebene möglich.
Im Datenmodell neu eingeführte Felder beeinflussen bestehende Abfragen nicht, können aber jederzeit in diese aufgenommen werden.
Felder, die zukünftig aus der API entfernt werden sollen, können mit isDeprecated als veraltet gekennzeichnet und ein Grund als Metainformation angegeben werden.
Diese Kennzeichnung beeinflusst die Abfrage des Feldes nicht, kann aber per Introspektion zur Entwicklungszeit von Tools abgefragt und dem Entwickler als Warnung angezeigt werden.
Enthält eine Abfrage Felder, die im Schema nicht mehr enthalten sind, schlägt die Abfrage fehl.
Änderungen in der Auswertungslogik einzelner Felder können über optionale Feldargumente bereitgestellt werden.
Auch diese beeinflussen bestehende Abfragen ohne diese Argumente nicht.
Für Feldargumente und Input Typen existiert zur Zeit noch keine Möglichkeit, diese als veraltet zu kennzeichnen, ist aber für den nächsten Release der GraphQL Spezifikation geplant.
Ein GraphQL Server stellt ein Schema und damit alle darin enthaltenen Abfragen unter einer URI bereit.
Ergibt sich die Notwendigkeit, eine neue Version unter einer anderen URI zu veröffentlichen, so können Abfragen die Schemata nicht verbinden und werden vom Server nur im Kontext eines Schemas ausgewertet.
\section{Performance}
Zum Vergleich der Abfrageperformance von GraphQL und REST wurden jeweils nacheinander eine Reihe von Abfragen durchgeführt und gemessen, um die Charakteristik der Daten zu erforschen.
Abgefragt wurde eine Liste von JSON-Objekten der Größe 16,7KB.
Abbildung~\ref{img:abfrage-sequenz} zeigt den Ablauf der Messungen im Sequenzdiagramm.
Die Zeitspanne A stellt die Verarbeitungszeit der ankommenden Anfrage bis zum Anfragen der Daten von der Datenbank bzw.\ dem Arbeitsspeicher dar.
Es wird erwartet, dass diese Zeitspanne bei GraphQL größer ist, da die Anfrage vom Server erst geparsed und validiert werden muss, um festzustellen welche Daten gelesen werden müssen.
Zeitspanne B ist die Bearbeitungszeit der Datenbank bis die Daten vom Server empfangen worden sind.
Beim Lesen der Daten aus dem Arbeitsspeicher wird diese Zeit minimal.
Dauer C zeigt die benötigte Zeit zum Auswerten und Senden der Daten bis diese beim Client empfangen wurden.
Auch diese Dauer wird vermutlich bei GraphQL länger sein, da die von der Datenquelle gelesenen Daten je nach Abfrage nicht direkt an den Client weitergeleitet werden können, während die REST API direkt mit den Daten aus der Datenbank antwortet.
Die Zeitspanne D ist die Verarbeitungszeit der Daten im Client, bis diese verwendet werden können.
Die Zeiten bis zum Empfangen (Received) und bis die Daten verwendbar sind (Parsed = Received + D) wurden vom Client für den Vergleich aufgezeichnet~\ref{code:measuring}.
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{abfrage-sequenz.png}
  \caption{Sequenzdiagramm Performancemessung}\label{img:abfrage-sequenz}
\end{figure}
\begin{figure}[h]
  \centering
  \begin{minted}{typescript}
    const startTime = performance.now();
    const response = await fetch('http://localhost:5000/events');
    const received = performance.now() - startTime;
    const data = await response.json();
    const parsed = performance.now() - startTime;
  \end{minted}
  \caption{Messung von Received- und Parsed-Zeit, Vereinfachte Darstellung aus \emph{EventFetch.vue} Z.~92f.}\label{code:measuring}
\end{figure}
\par
Die kostenfreie Laufzeitumgebung von Heroku (Dyno) unterliegt einem monatlichen Stundenlimit und wird nach 30 Minuten, in denen keine Anfragen gestellt werden, in den Schlafzustand versetzt.
Erhält eine schlafende Dyno eine Anfrage, so wird sie nach einer kurzen Verzögerung wieder aktiv~\cite[vgl.][]{Heroku}.
Die anfängliche Verzögerungszeit ist nach der angegebenen 30 minütigen Pause, in geringerem Maße aber auch nach nur wenigen Sekunden Inaktivität zu beobachten.\ref{img:abfrage-zeitverlauf}
Dadurch verursachte Ausreißer sind unabhängig von der verwendeten API, wurden aber aufgrund der hohen Schwankungen in den darauffolgenden Untersuchungen nicht einbezogen. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{abfragen-zeitverlauf.png}
  \caption{Abfragen im Zeitverlauf}\label{img:abfrage-zeitverlauf}
\end{figure}
Abbildung~\ref{img:abfrage-gerät} zeigt, dass GraphQL-Abfragen im Mittel länger dauern, als REST-Abfragen.
Ein Zusammenhang zwischen der mittleren Abfragezeit und den Geräten lässt sich kaum feststellen.
Außerdem dauern Anfragen allgemein im Mobilfunknetz nicht nur deutlich länger, sie streuen auch stärker.
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{abfrage-gerät2.png}
  \caption{Abfragen nach Gerät}\label{img:abfrage-gerät}
\end{figure}
In der Erwartung, dass der PC, aufgrund des besten Benchmarks~\cite{Benchmark}, die kürzesten Parsingzeiten haben würde, zeigt Abbildung~\ref{img:parsing-gerät} die Dauer, um die empfangenen Daten in JavaScript zu parsen, im Verhältnis zum PC.
Der Zusammenhang zwischen der CPU-Leistung und den Parsingzeiten bestätigt die Erwartung, wobei das Parsen im Mobilfunknetz jedoch mehr als doppelt so lange dauert, wie im WLAN.
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{parsing-gerät.png}
  \caption{Parsingzeiten nach Gerät}\label{img:parsing-gerät}
\end{figure}
\par
GraphQL und REST wurden in drei verschiedenen Verteilungsszenarien getestet.
\begin{enumerate}
  \item Daten im Hauptspeicher des Servers und Server in der Cloud
  \item Datenbank und Server in der Cloud
  \item Datenbank in der Cloud und Server im lokalen Netzwerk
\end{enumerate}
Bei allen Szenarien wird deutlich, das GraphQL-Abfragen im Mittel 26\% länger dauern, als  REST-Abfragen~\ref{tab:graphql-rest}.
Es lässt sich schließen, dass die Parsingzeiten bei leistungsstärkeren Geräten besser ist, der Unterschied zwischen WLAN und Mobilfunknetz jedoch deutlich größeren Einfluss auf das Gesamtergebnis hat.
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{performance-szenario.png}
  \caption{Abfrageperformance nach Testszenario}\label{img:performance-szenario}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{performance-diff.png}
  \caption{Performancedifferenz GraphQL-REST}\label{img:performance-diff}
\end{figure}

\section{Datenaufkommen}
Besonders bei schlechter Konnektivität sind die von einer API empfangenen Datenmengen entscheidender Einflussfaktor für die Anwendungsperformance.
Werden mehr Daten transferiert, so nehmen auch Verarbeitungszeit und Speicherbelastung zu.
Daher sollte das Übertragen nicht genutzter Daten (Overfetching) vermieden werden.
GraphQL sendet standardmäßig die kleinstmögliche Datenmenge, da der Client gezwungen ist, jedes benötigte Feld anzugeben.
Bei sehr kleine Datenmengen, die häufig abgefragt werden, muss beachtet werden, dass mit jedem Request auch die GraphQL-Query übertragen wird und die übertragene Datenmenge erhöht.
Eine REST-Antwort enthält normalerweise die gesamte Repräsentation der Ressource.
Wird nur ein kleiner Teil einer Repräsentation benötigt, so sollte der Server Feldselektion für diese Ressource unterstützen oder ein angepasster Endpunkt eingeführt werden.
Je spezieller die Anforderungen an einen Endpunkt sind, desto mehr Daten müssen im Request übertragen werden.
Tests können helfen einzuschätzen, ob das präzisieren des Requests eine ausreichende Datenreduktion in der Antwort zur Folge hat.

\section{Caching}
% \begin{itemize}
%   \item Flexibilität gegen Caching: je spezieller die Abfrage, desto schwieriger (weniger sinnvoll) caching
%   \item nicht Antwort direkt cachen (HTTP), sondern manuell Objekte anhand ID cachen (JavaScript)
%   \item REST
%   \begin{itemize}
%     \item Browser HTTP caching automatisch genutzt
%     \item Caching basierend auf Endpunkt
%     \item URL ist cache ID für die Ressource
%     \item ermöglicht HTTP cache proxies
%     \item je spezieller der query string, desto weniger cache Treffer
%   \end{itemize}
%   \item GraphQL
%   \begin{itemize}
%     \item POST response wird normalerweise nicht gecacht
%     \item standardmäßig keine ID für caching vorhanden. Empfehlung: API sollte ID pro Objekt bereitstellen
%     \item globale ID über alle Tabellen/Backendservices nötig, mit schema typ verbinden
%     \item einzelne queries cachen aufgrund verschachtelung nicht sinnvoll, objekte aus query extrahieren
%   \end{itemize}
% \end{itemize}
Wird eine Anwendung über einen längeren Zeitraum oder in kurzen Abständen hintereinander genutzt, so kann sich der Einsatz von clientseitigem Caching lohnen.
Ein Cache speichert Daten einer Antwort anhand eines Schlüssels für zukünftige gleiche Anfragen. 
REST kann davon profitieren, dass Browser HTTP GET-Requests automatisch cachen.
Der Schlüssel ist in diesem Fall die URI der Anfrage.
Je mehr die URIs jedoch durch das Anhängen von Query Strings modifiziert werden, desto öfter kann im Cache kein passender Schlüssel gefunden werden und der Vorteil des nativen Browsercaches wird verringert.
GraphQL kommuniziert üblicherweise mit POST Requests, welche nicht implizit gecacht werden.
Tools wie Relay~\cite{Relay} implementieren einen Cache mittels JavaScript, indem sie Objekte einer GraphQL-Antwort anhand einer ID cachen und vor dem Absenden neuer Anfragen die anzufragenden Objekte mit den gecachten Daten vergleichen.
Diese Art von manuellem Caching ist für JavaScript-Clients möglich, nicht jedoch für Zwischenkomponenten im Netzwerk.

% \section{Batching/Deduping}
% \begin{itemize}
%   \item GraphQL queries können parallel ausgewertet werden, Mutations nicht
%   \item Dataloader verhindert gleiche Daten mehrmals Anforderungen
%   \item wartet auf alle Resolver, minimale Anzahl requests ausgeführt
% \end{itemize}

% \section{Fehlerbehandlung}
% \begin{itemize}
%   \item GraphQL gibt error Feld zurück
%   \item 200 OK auch bei Fehler
% \end{itemize}

% \section{Sicherheit}
% \begin{itemize}
%   \item queries können komplex werden und server stark belasten
%   \item apollo safe listing: tatsächlich genutzte Queries zur Entwicklungszeit extrahieren und whitelisten
%   \item nur query id schicken, ast kann vorher berechnet werden -> schnellere ausführung, nicht möglich bei public api
%   \item angriffe und missbrauch vermeiden
% \end{itemize}

% \section{Kosten}

% \section{Lernkurve, Fehlersuche, Community}

% \section{Bibliotheken und Tools}
% \begin{itemize}
%   \item GraphQL
%   \begin{itemize}
%     \item offizielle Spezifikation vorhanden
%     \item Referenzimplementierung in JavaScript
%     \item Zusatztools von Facebook (Dataloader, Relay)
%     \item Tool kann Abfragekomplexität zu Entwicklungszeit ermitteln (mit vergangenen Messwerten)
%     \item Introspektion hilft, statische Validierung (type checking)
%     \item Apollo Client/server: Laufzeitanalyse, graphnutzung und graphänderungen tracken
%   \end{itemize}
%   \item REST: fehlende Standards (in Bezug auf linkelemente) macht die Entwicklung von Tools schwierig
% \end{itemize}
